{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "approved-andrew",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "geological-brooks",
   "metadata": {},
   "source": [
    "Test and training data with their associated labels have been acquired from an academic dataset (not available in this repo due to size >700MB). The actual content of these datasets is not entirely certain, but likely to be small image data labelled into several categories. The goal is to build neural network models with PyTorch that classify the data to the labels.  \n",
    "Initially, a simple neural network is built, followed by a convolutional neural network. These are run here on a CPU, but the code is written to run on a GPU where available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worth-extreme",
   "metadata": {},
   "source": [
    "# Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "musical-capital",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T17:22:28.852774Z",
     "start_time": "2021-09-13T17:22:28.069519Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ethical-smart",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T17:22:29.295617Z",
     "start_time": "2021-09-13T17:22:28.855807Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "train_data = torch.load('train_data_2')\n",
    "test_data = torch.load('test_data_2')\n",
    "\n",
    "train_labels = torch.load('train_labels_2').long()\n",
    "test_labels = torch.load('test_labels_2').long()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chemical-separate",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "electrical-steam",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T17:22:29.317901Z",
     "start_time": "2021-09-13T17:22:29.299053Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([50000, 3, 32, 32]), torch.Size([10000, 3, 32, 32]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the shape of the data\n",
    "train_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "objective-steel",
   "metadata": {},
   "source": [
    "The data appears to be colour images (3 channel) of 32x32 pixels. We can test this by plotting a sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "communist-independence",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T17:22:29.923083Z",
     "start_time": "2021-09-13T17:22:29.320876Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Corresponding Label is: 7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "sample_num=141\n",
    "print(f'The Corresponding Label is: {train_labels[sample_num]}')\n",
    "plt.imshow(train_data[sample_num][0], cmap='nipy_spectral')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparable-cooling",
   "metadata": {},
   "source": [
    "This is clearly an image of a horse, despite being unable to find the exact colourmap to a make it look natural. It is worth examining the labels to have an idea of how many categories this data is to be classified into."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "defensive-parliament",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T17:22:31.144304Z",
     "start_time": "2021-09-13T17:22:29.926503Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(9))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the min and max values of the labels\n",
    "min(train_labels), max(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "guilty-investigation",
   "metadata": {},
   "source": [
    "There appear to be 10 output categories for this data, so the neural network should have 10 outputs.\n",
    "Additionally, the data needs to be flattened before use in the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "residential-maria",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T17:22:31.159190Z",
     "start_time": "2021-09-13T17:22:31.150071Z"
    }
   },
   "outputs": [],
   "source": [
    "# Flatten data tensors\n",
    "train_data = train_data.view(train_data.shape[0], train_data.shape[1] * train_data.shape[2] * train_data.shape[3])\n",
    "test_data = test_data.view(test_data.shape[0], test_data.shape[1] * test_data.shape[2] * test_data.shape[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "optional-bouquet",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T17:22:31.180210Z",
     "start_time": "2021-09-13T17:22:31.165697Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50000, 3072]) torch.Size([10000, 3072])\n",
      "torch.FloatTensor torch.FloatTensor\n",
      "torch.LongTensor torch.LongTensor\n"
     ]
    }
   ],
   "source": [
    "# Check data shapes and types are correct for PyTorch\n",
    "print(train_data.shape, test_data.shape)\n",
    "print(train_data.type(), test_data.type())\n",
    "print(train_labels.type(), test_labels.type())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "honest-episode",
   "metadata": {},
   "source": [
    "# Simple Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specialized-counter",
   "metadata": {},
   "source": [
    "## Build and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "consistent-catalog",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T17:22:31.200112Z",
     "start_time": "2021-09-13T17:22:31.183908Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the parameters of the simple neural network\n",
    "class Simple_NN(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_features):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(n_features, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x)) # ReLU activation function used for hidden layers\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        # Log softmax is an activation function that normalizes the category scores, and the log also increases penalty of incorrect classification\n",
    "        x = F.log_softmax(self.fc4(x), dim = 1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abandoned-massachusetts",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T17:22:31.227179Z",
     "start_time": "2021-09-13T17:22:31.203299Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on the CPU\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Simple_NN(\n",
       "  (fc1): Linear(in_features=3072, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (fc3): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Push processing onto GPU if available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print(\"running on the GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"running on the CPU\")\n",
    "\n",
    "net = Simple_NN(n_features = 3072)\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "tested-infrastructure",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T17:22:31.237555Z",
     "start_time": "2021-09-13T17:22:31.230057Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define loss function and optimizer to use\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer =  torch.optim.SGD(net.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "golden-burton",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T17:24:25.757558Z",
     "start_time": "2021-09-13T17:22:31.242106Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:06<00:00, 83.16it/s]\n",
      "  2%|▏         | 8/500 [00:00<00:06, 76.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.8367, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:05<00:00, 87.93it/s]\n",
      "  2%|▏         | 8/500 [00:00<00:06, 78.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.7420, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:05<00:00, 90.39it/s]\n",
      "  1%|          | 6/500 [00:00<00:08, 58.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.7305, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:05<00:00, 89.78it/s]\n",
      "  1%|          | 6/500 [00:00<00:08, 58.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6846, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:05<00:00, 90.21it/s]\n",
      "  2%|▏         | 9/500 [00:00<00:05, 83.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6278, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:05<00:00, 87.33it/s]\n",
      "  1%|          | 6/500 [00:00<00:08, 57.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.5544, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:05<00:00, 84.05it/s]\n",
      "  2%|▏         | 9/500 [00:00<00:05, 83.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.5473, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:05<00:00, 87.51it/s]\n",
      "  2%|▏         | 8/500 [00:00<00:06, 75.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.4593, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:05<00:00, 88.84it/s]\n",
      "  2%|▏         | 9/500 [00:00<00:05, 83.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.4442, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:05<00:00, 90.25it/s]\n",
      "  2%|▏         | 9/500 [00:00<00:05, 86.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.3929, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:05<00:00, 91.01it/s]\n",
      "  2%|▏         | 9/500 [00:00<00:05, 89.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.3733, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:05<00:00, 90.71it/s]\n",
      "  2%|▏         | 9/500 [00:00<00:06, 81.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.3148, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:05<00:00, 88.11it/s]\n",
      "  1%|▏         | 7/500 [00:00<00:07, 69.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.3019, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:06<00:00, 82.11it/s]\n",
      "  2%|▏         | 8/500 [00:00<00:06, 75.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.2390, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:05<00:00, 89.74it/s]\n",
      "  2%|▏         | 9/500 [00:00<00:05, 86.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.2757, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:05<00:00, 88.73it/s]\n",
      "  1%|          | 6/500 [00:00<00:08, 58.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.2307, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:05<00:00, 89.81it/s]\n",
      "  2%|▏         | 8/500 [00:00<00:06, 77.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1659, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:06<00:00, 75.67it/s]\n",
      "  2%|▏         | 9/500 [00:00<00:05, 86.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1537, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:05<00:00, 89.18it/s]\n",
      "  2%|▏         | 8/500 [00:00<00:06, 77.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1802, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:05<00:00, 86.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1142, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "BATCH_SIZE = 100\n",
    "for epoch in range (epochs):\n",
    "    for i in tqdm(range(0,len(train_data), BATCH_SIZE)): # Use tqdm to show progress bars\n",
    "        # Batch the data\n",
    "        batch_data = train_data[i:i+BATCH_SIZE]\n",
    "        batch_labels = train_labels[i:i+BATCH_SIZE]\n",
    "        batch_data = batch_data.to(device)\n",
    "        batch_labels = batch_labels.to(device)\n",
    "        \n",
    "        net.zero_grad()  # Set gradients to 0 before loss calculation\n",
    "        output = net(batch_data)  # Pass in the reshaped batch\n",
    "        \n",
    "        loss = loss_function(output, batch_labels)  # Calculate the loss value\n",
    "        loss.backward()  # Apply the loss backwards through the network's parameters\n",
    "        optimizer.step()  # Optimize weights to account for loss/gradients\n",
    "    \n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "classified-ground",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "historical-memorial",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T17:24:26.222514Z",
     "start_time": "2021-09-13T17:24:25.759918Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4, 9, 8, 0, 4, 6, 3, 6, 3, 1])\n",
      "tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1])\n"
     ]
    }
   ],
   "source": [
    "# Use the model to predict from the test set\n",
    "with torch.no_grad():\n",
    "    predicted = net.forward(test_data.to(device))\n",
    "    predicted_classes = torch.argmax(predicted, dim = 1)\n",
    "    \n",
    "    # The model seems to predict fairly well but still makes some mistakes\n",
    "    print(predicted_classes[0:10])\n",
    "    print(test_labels[0:10])\n",
    "    \n",
    "# Push data back onto CPU for further analysis\n",
    "device = torch.device('cpu')\n",
    "predicted_classes = predicted_classes.to(device)\n",
    "test_labels = test_labels.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cosmetic-arnold",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T17:24:26.451576Z",
     "start_time": "2021-09-13T17:24:26.226450Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.504\n"
     ]
    }
   ],
   "source": [
    "# Find accuracy metric for prediction on test set\n",
    "correct = 0\n",
    "total = 0\n",
    "for i in range(len(predicted_classes)):\n",
    "\n",
    "    if predicted_classes[i] == test_labels[i]:\n",
    "        correct += 1\n",
    "    total += 1\n",
    "print(\"Accuracy: \", round(correct/total, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "matched-hughes",
   "metadata": {},
   "source": [
    "This model has given 50% accuracy. This can be compared to a convolutional model to see if this can be improved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confused-junction",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liked-madness",
   "metadata": {},
   "source": [
    "## Reload the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fantastic-garlic",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T17:24:26.888743Z",
     "start_time": "2021-09-13T17:24:26.454608Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([50000, 3, 32, 32]), torch.Size([10000, 3, 32, 32]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As the data was previously converted to the long format, this loses 2d spatial information. The data is therefore reloaded\n",
    "train_data = torch.load('train_data_2')\n",
    "test_data = torch.load('test_data_2')\n",
    "train_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "figured-simulation",
   "metadata": {},
   "source": [
    "## Build and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "buried-broad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T17:24:26.905755Z",
     "start_time": "2021-09-13T17:24:26.893625Z"
    }
   },
   "outputs": [],
   "source": [
    "# A 2-dimensional CNN is used as this typically performs best with 2D image data\n",
    "\n",
    "class Conv_NN(nn.Module):\n",
    "    def __init__(self, n_channels):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.cnn_layers = nn.Sequential(\n",
    "            # Define a 2D convolution layer\n",
    "            nn.Conv2d(in_channels = n_channels, out_channels = 16, kernel_size=4, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(16), # Batch normalisation standardises inputs to improve training performance\n",
    "            nn.ReLU(inplace=True), # Using the same activation function as with the Simple NN\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), # Max pooling to help extract sharp features e.g. edges\n",
    "            # Define another 2D convolution layer\n",
    "            nn.Conv2d(16, 8, kernel_size=4, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2) # Average pooling to help extract smooth image features\n",
    "        )\n",
    "        \n",
    "        # Add linear layers to get to 10 outputs\n",
    "        self.linear_layers = nn.Sequential(\n",
    "            nn.Flatten(), # Flatten the input\n",
    "            nn.Linear(200, 100),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(100, 10)\n",
    "        )\n",
    "\n",
    "    # Define the forward function\n",
    "    def forward(self, x):\n",
    "        x = self.cnn_layers(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.linear_layers(x)\n",
    "        return x    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "assisted-string",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T17:24:26.921954Z",
     "start_time": "2021-09-13T17:24:26.909217Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv_NN(\n",
      "  (cnn_layers): Sequential(\n",
      "    (0): Conv2d(3, 16, kernel_size=(4, 4), stride=(1, 1))\n",
      "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(16, 8, kernel_size=(4, 4), stride=(1, 1))\n",
      "    (5): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  )\n",
      "  (linear_layers): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=200, out_features=100, bias=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Linear(in_features=100, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model and check the steps\n",
    "net = Conv_NN(n_channels = 3)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "theoretical-metadata",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T17:24:26.942862Z",
     "start_time": "2021-09-13T17:24:26.925754Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on the CPU\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Conv_NN(\n",
       "  (cnn_layers): Sequential(\n",
       "    (0): Conv2d(3, 16, kernel_size=(4, 4), stride=(1, 1))\n",
       "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Conv2d(16, 8, kernel_size=(4, 4), stride=(1, 1))\n",
       "    (5): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  )\n",
       "  (linear_layers): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=200, out_features=100, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Linear(in_features=100, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Push processing onto GPU if available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print(\"running on the GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"running on the CPU\")\n",
    "\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "occupied-practice",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T17:24:26.958294Z",
     "start_time": "2021-09-13T17:24:26.950820Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "increasing-skirt",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T17:29:53.368508Z",
     "start_time": "2021-09-13T17:24:26.961644Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2000 [00:00<?, ?it/s]/home/fj/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448216815/work/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "100%|██████████| 2000/2000 [00:32<00:00, 62.46it/s]\n",
      "  0%|          | 6/2000 [00:00<00:37, 53.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.4888, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:31<00:00, 63.64it/s]\n",
      "  0%|          | 6/2000 [00:00<00:36, 54.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1524, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:32<00:00, 61.95it/s]\n",
      "  0%|          | 5/2000 [00:00<00:47, 42.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0947, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:36<00:00, 55.32it/s]\n",
      "  0%|          | 5/2000 [00:00<00:44, 44.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0893, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:33<00:00, 59.75it/s]\n",
      "  0%|          | 5/2000 [00:00<00:46, 42.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0842, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:32<00:00, 61.29it/s]\n",
      "  0%|          | 4/2000 [00:00<00:49, 39.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1312, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:31<00:00, 62.90it/s]\n",
      "  0%|          | 6/2000 [00:00<00:33, 59.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1653, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:32<00:00, 62.20it/s]\n",
      "  0%|          | 5/2000 [00:00<00:40, 49.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1587, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:31<00:00, 63.65it/s]\n",
      "  0%|          | 4/2000 [00:00<00:51, 39.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1236, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:32<00:00, 60.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1089, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "BATCH_SIZE = 25\n",
    "for epoch in range (epochs):\n",
    "    for i in tqdm(range(0,len(train_data), BATCH_SIZE)): # Use tqdm to show progress bars\n",
    "        # Batch the data\n",
    "        batch_data = train_data[i:i+BATCH_SIZE]\n",
    "        batch_labels = train_labels[i:i+BATCH_SIZE]\n",
    "        batch_data = batch_data.to(device)\n",
    "        batch_labels = batch_labels.to(device)\n",
    "        \n",
    "        net.zero_grad()  # Set gradients to 0 before loss calculation\n",
    "        output = net(batch_data)  # Pass in the batch\n",
    "        \n",
    "        loss = loss_function(output, batch_labels)  # Calculate the loss value\n",
    "        loss.backward()  # Apply the loss backwards through the network's parameters\n",
    "        optimizer.step()  # Optimize weights to account for loss/gradients\n",
    "    \n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southeast-strap",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "surgical-department",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T17:29:55.855010Z",
     "start_time": "2021-09-13T17:29:53.371152Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 9])\n",
      "tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1])\n"
     ]
    }
   ],
   "source": [
    "# Use the model to predict from the test set\n",
    "with torch.no_grad():\n",
    "    predicted = net.forward(test_data.to(device))\n",
    "    predicted_classes = torch.argmax(predicted, dim = 1)\n",
    "    \n",
    "    # The model seems to predict well with fewer mistakes\n",
    "    print(predicted_classes[0:10])\n",
    "    print(test_labels[0:10])\n",
    "    \n",
    "# Push data back onto CPU for further analysis\n",
    "device = torch.device('cpu')\n",
    "predicted_classes = predicted_classes.to(device)\n",
    "test_labels = test_labels.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "olive-professional",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T17:29:56.116424Z",
     "start_time": "2021-09-13T17:29:55.857834Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.638\n"
     ]
    }
   ],
   "source": [
    "# Find accuracy metric for prediction on test set\n",
    "correct = 0\n",
    "total = 0\n",
    "for i in range(len(predicted_classes)):\n",
    "\n",
    "    if predicted_classes[i] == test_labels[i]:\n",
    "        correct += 1\n",
    "    total += 1\n",
    "print(\"Accuracy: \", round(correct/total, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "elegant-mechanics",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-13T17:29:58.602987Z",
     "start_time": "2021-09-13T17:29:56.119679Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[653,  29,  70,  21,  29,   5,  10,  15, 121,  47],\n",
       "       [ 27, 790,  13,   3,   7,   5,  12,   5,  39,  99],\n",
       "       [ 70,  13, 482,  62, 117,  59,  99,  61,  23,  14],\n",
       "       [ 25,  20,  86, 396, 115, 121, 121,  72,  22,  22],\n",
       "       [ 21,  12,  81,  52, 575,  18, 108, 106,  20,   7],\n",
       "       [ 17,   7,  88, 206,  61, 440,  54, 109,   9,   9],\n",
       "       [  6,   4,  36,  42,  42,  13, 832,  10,  10,   5],\n",
       "       [ 22,   8,  37,  42,  71,  40,  19, 735,   2,  24],\n",
       "       [ 90,  63,  11,  27,  13,   3,  10,   7, 728,  48],\n",
       "       [ 34,  87,   7,  10,   9,   2,  17,  35,  51, 748]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(test_labels, predicted_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spanish-offset",
   "metadata": {},
   "source": [
    "The convolutional model has given a good increase over the simple NN, now up to 64% accuracy. It appears that classes 2, 3, and 4 were more difficult to classify, showing misclassifications into several classes. Also, there are noticeable peaks in misclassification where class 8 and class 0 have been misclassified as each other, as were classes 5 and 3, and classes 9 and 1. This suggests there may be some common features between these class pairs that the model is identifying and causing the misclassifications observed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contrary-enhancement",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "driving-exhaust",
   "metadata": {},
   "source": [
    "Both models performed fairly well once optimized. One noticeable issue worth mentioning with the simple NN was the learning rate used, which was relatively high. Looking at the error values, after a certain number of epochs we saw that learning rates actually increased slightly, and the final model did not have the lowest error of all the epochs. This would suggest that the model was overadjusting in gradient descent and overshooting the minimum error of the model. However, the higher learning rate did bring the error down quickly in earlier epochs, so a stepped learning rate could be useful here, e.g. by using the StepLR or MultiStepLR function in the optimizer. Alternatively, it appears that a learning rate schedule that uses decay or momentum, e.g. the Adam optimizer, could significantly benefit this model in helping it to converge.  \n",
    "\n",
    "This strategy could also be applied to the CNN to hone in on a minimum for the error function. However, the CNN was significantly reducing error over each epoch, so a first strategy to improving the CNN model may simply be to run more epochs, with the possible addition of a more complex learning rate schedule."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frequent-prototype",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "diverse-protocol",
   "metadata": {},
   "source": [
    "1) https://www.freecodecamp.org/news/an-intuitive-guide-to-convolutional-neural-networks-260c2de0a050/  \n",
    "2) https://www.analyticsvidhya.com/blog/2019/10/building-image-classification-models-cnn-pytorch/  \n",
    "3) https://pytorch.org/docs/stable/generated/torch.nn.Module.html  \n",
    "4) https://www.geeksforgeeks.org/adjusting-learning-rate-of-a-neural-network-in-pytorch/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
